{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9e7215",
   "metadata": {},
   "source": [
    "# 01 Data Preparation\n",
    "**German Energy Demand Forecasting**\n",
    "\n",
    "## ðŸ“Š Data Sources:\n",
    "- **SMARD / Bundesnetzagentur** Hourly realized electricity load for Germany, Time span: 2015â€“2024 [https://www.smard.de/home/downloadcenter/download-marktdaten/]\n",
    "- **Weather data** Daily observations from selected DWD weather stations [https://www.dwd.de/DE/leistungen/klimadatendeutschland/klarchivstunden.html] \n",
    "- **Calender Data** Python `holidays` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4703d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import holidays\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pfade setzen\n",
    "os.chdir(Path('../data/raw').resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ffef0",
   "metadata": {},
   "source": [
    "## SMARD Energy Data (2015-2024)\n",
    "Weather data is merged at the daily level using calendar dates. Missing values and time alignment issues (e.g. daylight saving time) are handled during this step to ensure consistency across time scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d395b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Shape: (87672, 6)\n",
      "Duplicates: 20 observations\n",
      "Clean Shape: (87662, 6)\n",
      "Time Span: 2015-01-01 00:00:00 â†’ 2024-12-31 23:00:00\n",
      "Load Range: 30,903 - 81,320 MWh\n",
      "\n",
      "Preview:\n",
      "                     load_mwh  hour       date   weekday  month  year\n",
      "Datetime                                                             \n",
      "2015-01-01 00:00:00  44600.25     0 2015-01-01  Thursday      1  2015\n",
      "2015-01-01 01:00:00  43454.75     1 2015-01-01  Thursday      1  2015\n",
      "2015-01-01 02:00:00  41963.25     2 2015-01-01  Thursday      1  2015\n",
      "2015-01-01 03:00:00  40617.75     3 2015-01-01  Thursday      1  2015\n",
      "2015-01-01 04:00:00  39936.75     4 2015-01-01  Thursday      1  2015\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "energy_1516 = pd.read_csv(\"Realisierter_Stromverbrauch_201501010000_201701010000_Stunde.csv\", sep=\";\")\n",
    "energy_1718 = pd.read_csv(\"Realisierter_Stromverbrauch_201701010000_201901010000_Stunde.csv\", sep=\";\")\n",
    "energy_1920 = pd.read_csv(\"Realisierter_Stromverbrauch_201901010000_202101010000_Stunde.csv\", sep=\";\")\n",
    "energy_2122 = pd.read_csv(\"Realisierter_Stromverbrauch_202101010000_202301010000_Stunde.csv\", sep=\";\")\n",
    "energy_2324 = pd.read_csv(\"Realisierter_Stromverbrauch_202301010000_202501010000_Stunde.csv\", sep=\";\")\n",
    "\n",
    "energy_hour = pd.concat([energy_1516, energy_1718, energy_1920, energy_2122, energy_2324], ignore_index=True)\n",
    "\n",
    "# Set Index\n",
    "\n",
    "energy_hour[\"Datetime\"] = pd.to_datetime(energy_hour[\"Datum von\"], dayfirst=True)\n",
    "energy_hour = energy_hour.set_index(\"Datetime\").sort_index()\n",
    "\n",
    "# Daylight Saving Time Fix\n",
    "\n",
    "print(f\"Raw Shape: {energy_hour.shape}\")\n",
    "dupes = energy_hour[energy_hour.index.duplicated(keep=False)]\n",
    "print(f\"Duplicates: {len(dupes)} observations\")\n",
    "energy_hour = energy_hour[~energy_hour.index.duplicated(keep=\"first\")]\n",
    "print(f\"Clean Shape: {energy_hour.shape}\")\n",
    "\n",
    "# Clean Data\n",
    "\n",
    "energy_hour = energy_hour.rename(columns={\"Netzlast [MWh] Berechnete AuflÃ¶sungen\": \"load_mwh\"})\n",
    "energy_hour[\"load_mwh\"] = (\n",
    "    energy_hour[\"load_mwh\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\".\", \"\", regex=False)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "energy_hour = energy_hour[[\"load_mwh\"]].assign(\n",
    "    hour=energy_hour.index.hour,\n",
    "    date=energy_hour.index.normalize(),\n",
    "    weekday=energy_hour.index.day_name(),\n",
    "    month=energy_hour.index.month,\n",
    "    year=energy_hour.index.year,\n",
    ")\n",
    "\n",
    "energy_hour[\"weekday\"] = pd.Categorical(\n",
    "    energy_hour[\"weekday\"],\n",
    "    categories=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(f\"Time Span: {energy_hour.index.min()} â†’ {energy_hour.index.max()}\")\n",
    "print(f\"Load Range: {energy_hour['load_mwh'].min():,.0f} - {energy_hour['load_mwh'].max():,.0f} MWh\")\n",
    "print(\"\\nPreview:\")\n",
    "print(energy_hour.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093d760",
   "metadata": {},
   "source": [
    "### Daily Energy Aggregation\n",
    "\n",
    "**Daily sums for Weather Merge + Long-term Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625e4cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Shape: (3653, 6)\n",
      "Daily Span: 2015-01-01 00:00:00 â†’ 2024-12-31 00:00:00\n",
      "Daily Range: 864,718 - 1,729,547 MWh\n",
      "\n",
      "Daily Preview:\n",
      "              load_mwh   weekday  dayofweek  week  month  year\n",
      "date                                                          \n",
      "2015-01-01  1096852.75  Thursday          3     1      1  2015\n",
      "2015-01-02  1288914.75    Friday          4     1      1  2015\n",
      "2015-01-03  1213309.50  Saturday          5     1      1  2015\n",
      "2015-01-04  1177896.00    Sunday          6     1      1  2015\n",
      "2015-01-05  1425927.50    Monday          0     2      1  2015\n"
     ]
    }
   ],
   "source": [
    "energy_day = (\n",
    "    energy_hour\n",
    "    .groupby(\"date\", as_index=True)\n",
    "    .agg(load_mwh=(\"load_mwh\", \"sum\"))\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "energy_day = energy_day.assign(\n",
    "    weekday=energy_day.index.day_name(),\n",
    "    dayofweek=energy_day.index.dayofweek,  \n",
    "    week=energy_day.index.isocalendar().week.astype(int),\n",
    "    month=energy_day.index.month,\n",
    "    year=energy_day.index.year, \n",
    ")\n",
    "\n",
    "energy_day[\"weekday\"] = pd.Categorical(\n",
    "    energy_day[\"weekday\"],\n",
    "    categories=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(f\"Daily Shape: {energy_day.shape}\")\n",
    "print(f\"Daily Span: {energy_day.index.min()} â†’ {energy_day.index.max()}\")\n",
    "print(f\"Daily Range: {energy_day['load_mwh'].min():,.0f} - {energy_day['load_mwh'].max():,.0f} MWh\")\n",
    "print(\"\\nDaily Preview:\")\n",
    "print(energy_day.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260786b",
   "metadata": {},
   "source": [
    "## DWD Weather Data (2015-2024)\n",
    "\n",
    "**Daily TMK (Temperature)**\n",
    "\n",
    "5 Stations â†’ Daily Mean Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680d4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Shape: (3653, 2)\n",
      "Weather Span: 2015-01-01 00:00:00 â†’ 2024-12-31 00:00:00\n",
      "TMK Range: -9.0Â°C - 27.8Â°C\n",
      "\n",
      "Weather Preview:\n",
      "        date   TMK\n",
      "0 2015-01-01  1.00\n",
      "1 2015-01-02  3.28\n",
      "2 2015-01-03  3.20\n",
      "3 2015-01-04  2.76\n",
      "4 2015-01-05  2.36\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "weather1 = pd.read_csv(\"klarchiv_00433_daily_his/produkt_klima_tag_19480101_20241231_00433.txt\", sep=\";\")\n",
    "weather2 = pd.read_csv(\"klarchiv_01078_daily_his/produkt_klima_tag_19520101_20241231_01078.txt\", sep=\";\")\n",
    "weather3 = pd.read_csv(\"klarchiv_01262_daily_his/produkt_klima_tag_19920517_20241231_01262.txt\", sep=\";\")\n",
    "weather4 = pd.read_csv(\"klarchiv_01975_daily_his/produkt_klima_tag_19360101_20241231_01975.txt\", sep=\";\")\n",
    "weather5 = pd.read_csv(\"klarchiv_04931_daily_his/produkt_klima_tag_19530101_20241231_04931.txt\", sep=\";\")\n",
    "\n",
    "weather = pd.concat([weather1, weather2, weather3, weather4, weather5], ignore_index=True)\n",
    "weather.columns = weather.columns.str.strip()\n",
    "weather[\"date\"] = pd.to_datetime(weather[\"MESS_DATUM\"], format=\"%Y%m%d\")\n",
    "\n",
    "# 2015-2024 + TMK only\n",
    "weather = weather[\n",
    "    (weather[\"date\"] >= \"2015-01-01\") & \n",
    "    (weather[\"date\"] <= \"2024-12-31\")\n",
    "][[\"date\", \"STATIONS_ID\", \"TMK\"]].copy()\n",
    "\n",
    "# Missing Values (-999 â†’ NaN)\n",
    "weather[\"TMK\"] = weather[\"TMK\"].replace(-999, np.nan)\n",
    "\n",
    "# Daily Mean Temperature (5 Stations)\n",
    "weather_mean = weather.groupby(\"date\")[\"TMK\"].mean().reset_index()\n",
    "weather_mean[\"date\"] = pd.to_datetime(weather_mean[\"date\"])\n",
    "\n",
    "print(f\"Weather Shape: {weather_mean.shape}\")\n",
    "print(f\"Weather Span: {weather_mean['date'].min()} â†’ {weather_mean['date'].max()}\")\n",
    "print(f\"TMK Range: {weather_mean['TMK'].min():.1f}Â°C - {weather_mean['TMK'].max():.1f}Â°C\")\n",
    "print(\"\\nWeather Preview:\")\n",
    "print(weather_mean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96bbdc9",
   "metadata": {},
   "source": [
    "## Data-driven Holiday Detection\n",
    "\n",
    "**IQR Outlier Analysis**\n",
    "\n",
    "1. **National Holidays** (`holidays.DE()`): 36/38 weekday-outliers explained \n",
    "2. **Remaining 2 outliers** â†’ Fronleichnam (2023-06-08, 2024-05-30)  \n",
    "3. **Final `is_holiday`**: National + Fronleichnam â†’ 38/38 coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116c08ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 / 38 = 94.7% â†’ National Holidays\n",
      "\n",
      "Remaining Outliers (Fronleichnam):\n",
      "             load_mwh   weekday  dayofweek  week  month  year  is_holiday\n",
      "date                                                                     \n",
      "2023-06-08  1072759.0  Thursday          3    23      6  2023           0\n",
      "2024-05-30  1097436.0  Thursday          3    22      5  2024           0\n"
     ]
    }
   ],
   "source": [
    "# National Holidays\n",
    "de_holidays = holidays.DE(years=range(2015, 2025))\n",
    "energy_day['is_holiday'] = energy_day.index.map(\n",
    "    lambda x: 1 if x in de_holidays else 0\n",
    ")\n",
    "\n",
    "# IQR Outlier Analysis (by weekday)\n",
    "outliers = []\n",
    "for wd, df_wd in energy_day.groupby('weekday'):\n",
    "    q1 = df_wd['load_mwh'].quantile(0.25)\n",
    "    q3 = df_wd['load_mwh'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    \n",
    "    df_out = df_wd[(df_wd['load_mwh'] < lower) | (df_wd['load_mwh'] > upper)]\n",
    "    outliers.append(df_out)\n",
    "\n",
    "outliers = pd.concat(outliers)\n",
    "\n",
    "# Check Outliers\n",
    "outliers['is_holiday'] = outliers.index.normalize().map(\n",
    "    lambda x: 1 if x in de_holidays else 0\n",
    ")\n",
    "print(f\"{outliers['is_holiday'].sum():,} / {len(outliers)} = 94.7% â†’ National Holidays\\n\")\n",
    "print(\"Remaining Outliers (Fronleichnam):\")\n",
    "print(outliers[outliers['is_holiday']==0])\n",
    "\n",
    "# REGIONAL: Fronleichnam\n",
    "fronleichnam_dates = {key: val for key, val in holidays.DE(subdiv = \"NW\", years=range(2015, 2025)).items() if val == 'Fronleichnam'}\n",
    "de_holidays = set(de_holidays.keys()) | set(fronleichnam_dates.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86b0f8",
   "metadata": {},
   "source": [
    "## Merge & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50213995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Shape: (87662, 8)\n",
      "Daily Shape:  (3653, 8)\n",
      "\n",
      "Preview (Hourly):\n",
      "                     load_mwh  hour       date   weekday  month  year  TMK  \\\n",
      "Datetime                                                                     \n",
      "2015-01-01 00:00:00  44600.25     0 2015-01-01  Thursday      1  2015  1.0   \n",
      "2015-01-01 01:00:00  43454.75     1 2015-01-01  Thursday      1  2015  1.0   \n",
      "2015-01-01 02:00:00  41963.25     2 2015-01-01  Thursday      1  2015  1.0   \n",
      "2015-01-01 03:00:00  40617.75     3 2015-01-01  Thursday      1  2015  1.0   \n",
      "2015-01-01 04:00:00  39936.75     4 2015-01-01  Thursday      1  2015  1.0   \n",
      "\n",
      "                     is_holiday  \n",
      "Datetime                         \n",
      "2015-01-01 00:00:00           1  \n",
      "2015-01-01 01:00:00           1  \n",
      "2015-01-01 02:00:00           1  \n",
      "2015-01-01 03:00:00           1  \n",
      "2015-01-01 04:00:00           1  \n",
      "\n",
      "Preview (Daily):\n",
      "              load_mwh   weekday  dayofweek  week  month  year  is_holiday  \\\n",
      "date                                                                         \n",
      "2015-01-01  1096852.75  Thursday          3     1      1  2015           1   \n",
      "2015-01-02  1288914.75    Friday          4     1      1  2015           0   \n",
      "2015-01-03  1213309.50  Saturday          5     1      1  2015           0   \n",
      "2015-01-04  1177896.00    Sunday          6     1      1  2015           0   \n",
      "2015-01-05  1425927.50    Monday          0     2      1  2015           0   \n",
      "\n",
      "             TMK  \n",
      "date              \n",
      "2015-01-01  1.00  \n",
      "2015-01-02  3.28  \n",
      "2015-01-03  3.20  \n",
      "2015-01-04  2.76  \n",
      "2015-01-05  2.36  \n"
     ]
    }
   ],
   "source": [
    "# Hourly Dataset\n",
    "energy_weather_hour = energy_hour.merge(\n",
    "    weather_mean.set_index('date'), \n",
    "    left_on='date', \n",
    "    right_index=True, \n",
    "    how=\"left\"\n",
    ")\n",
    "energy_weather_hour['is_holiday'] = energy_weather_hour.index.map(\n",
    "    lambda x: 1 if x.date() in de_holidays else 0\n",
    ")\n",
    "\n",
    "# Daily Dataset\n",
    "energy_weather_day = energy_day.merge(\n",
    "    weather_mean.set_index('date'), \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how=\"left\"\n",
    ")\n",
    "energy_weather_day['is_holiday'] = energy_weather_day.index.map(\n",
    "    lambda x: 1 if x.date() in de_holidays else 0\n",
    ")\n",
    "\n",
    "print(f\"Hourly Shape: {energy_weather_hour.shape}\")\n",
    "print(f\"Daily Shape:  {energy_weather_day.shape}\")\n",
    "\n",
    "print(\"\\nPreview (Hourly):\")\n",
    "print(energy_weather_hour.head())\n",
    "\n",
    "print(\"\\nPreview (Daily):\")\n",
    "print(energy_weather_day.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17af3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "energy_weather_hour.to_csv(\"../processed/energy_weather_hourly.csv\", index_label=\"datetime\")\n",
    "energy_weather_day.to_csv(\"../processed/energy_weather_daily.csv\", index_label=\"date\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
